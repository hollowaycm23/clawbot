{"type":"session","version":3,"id":"17781c71-ddf6-4b8b-9155-43e556c8c6a9","timestamp":"2026-02-02T17:55:05.214Z","cwd":"/home/holloway"}
{"type":"message","id":"879670b2","parentId":null,"timestamp":"2026-02-02T17:55:05.215Z","message":{"role":"assistant","content":[{"type":"text","text":"✅ New session started · model: lm-studio/qwen3-14b"}],"api":"openai-responses","provider":"openclaw","model":"delivery-mirror","usage":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"totalTokens":0,"cost":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"total":0}},"stopReason":"stop","timestamp":1770054905215}}
{"type":"custom","customType":"model-snapshot","data":{"timestamp":1770054905262,"provider":"lm-studio","modelApi":"openai-completions","modelId":"qwen3-14b"},"id":"2c603fa9","parentId":"879670b2","timestamp":"2026-02-02T17:55:05.262Z"}
{"type":"message","id":"5a90e695","parentId":"2c603fa9","timestamp":"2026-02-02T17:55:05.271Z","message":{"role":"user","content":[{"type":"text","text":"A new session was started via /new or /reset. Greet the user in your configured persona, if one is provided. Be yourself - use your defined voice, mannerisms, and mood. Keep it to 1-3 sentences and ask what they want to do. If the runtime model differs from default_model in the system prompt, mention the default model. Do not mention internal steps, files, tools, or reasoning.\n[message_id: 240]"}],"timestamp":1770054905266}}
{"type":"message","id":"35ce6711","parentId":"5a90e695","timestamp":"2026-02-02T17:55:05.347Z","message":{"role":"assistant","content":[],"api":"openai-completions","provider":"lm-studio","model":"qwen3-14b","usage":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"totalTokens":0,"cost":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"total":0}},"stopReason":"error","timestamp":1770054905269,"errorMessage":"Error rendering prompt with jinja template: \"After the optional system message, conversation roles must alternate user and assistant roles except for tool calls and results.\".\n\nThis is usually an issue with the model's prompt template. If you are using a popular model, you can try to search the model under lmstudio-community, which will have fixed prompt templates. If you cannot find one, you are welcome to post this issue to our discord or issue tracker on GitHub. Alternatively, if you know how to write jinja templates, you can override the prompt template in My Models > model settings > Prompt Template."}}
{"type":"custom","customType":"model-snapshot","data":{"timestamp":1770055243535,"provider":"lm-studio","modelApi":"openai-completions","modelId":"mistralai/devstral-small-2-2512"},"id":"06137e5f","parentId":"35ce6711","timestamp":"2026-02-02T18:00:43.535Z"}
{"type":"message","id":"26f9af87","parentId":"06137e5f","timestamp":"2026-02-02T18:00:43.544Z","message":{"role":"user","content":[{"type":"text","text":"Pre-compaction memory flush. Store durable memories now (use memory/YYYY-MM-DD.md; create memory/ if needed). If nothing to store, reply with NO_REPLY."}],"timestamp":1770055243539}}
{"type":"message","id":"0029342b","parentId":"26f9af87","timestamp":"2026-02-02T18:00:43.635Z","message":{"role":"assistant","content":[],"api":"openai-completions","provider":"lm-studio","model":"mistralai/devstral-small-2-2512","usage":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"totalTokens":0,"cost":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"total":0}},"stopReason":"error","timestamp":1770055243542,"errorMessage":"Error rendering prompt with jinja template: \"After the optional system message, conversation roles must alternate user and assistant roles except for tool calls and results.\".\n\nThis is usually an issue with the model's prompt template. If you are using a popular model, you can try to search the model under lmstudio-community, which will have fixed prompt templates. If you cannot find one, you are welcome to post this issue to our discord or issue tracker on GitHub. Alternatively, if you know how to write jinja templates, you can override the prompt template in My Models > model settings > Prompt Template."}}
{"type":"message","id":"80b9c80e","parentId":"0029342b","timestamp":"2026-02-02T18:00:43.674Z","message":{"role":"user","content":[{"type":"text","text":"[Telegram Japao Maejima (@hollowaycm) id:219225576 +5m 2026-02-02 15:00 GMT-3] /start\n[message_id: 243]"}],"timestamp":1770055243672}}
{"type":"message","id":"dac0a487","parentId":"80b9c80e","timestamp":"2026-02-02T18:00:43.734Z","message":{"role":"assistant","content":[],"api":"openai-completions","provider":"lm-studio","model":"mistralai/devstral-small-2-2512","usage":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"totalTokens":0,"cost":{"input":0,"output":0,"cacheRead":0,"cacheWrite":0,"total":0}},"stopReason":"error","timestamp":1770055243674,"errorMessage":"Error rendering prompt with jinja template: \"After the optional system message, conversation roles must alternate user and assistant roles except for tool calls and results.\".\n\nThis is usually an issue with the model's prompt template. If you are using a popular model, you can try to search the model under lmstudio-community, which will have fixed prompt templates. If you cannot find one, you are welcome to post this issue to our discord or issue tracker on GitHub. Alternatively, if you know how to write jinja templates, you can override the prompt template in My Models > model settings > Prompt Template."}}
